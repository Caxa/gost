import os
import pandas as pd
import joblib
import numpy as np
import scipy.sparse as sp
from docx import Document
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
def extract_docx_features(filepath, label):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç, —à—Ä–∏—Ñ—Ç –∏ —Å—Ç–∏–ª—å –∏–∑ .docx."""
    doc = Document(filepath)
    features = []

    for para in doc.paragraphs:
        for run in para.runs:
            features.append({
                "text": para.text.strip(),
                "font_name": run.font.name,
                "font_size": run.font.size.pt if run.font.size else None,
                "bold": run.bold,
                "italic": run.italic,
                "label": label
            })

    return features

# –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–ø–∫–∏ datasets/
def load_dataset():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
    dataset = []

    for label, folder in [(1, "datasets/correct"), (0, "datasets/incorrect")]:
        if os.path.exists(folder):
            for filename in os.listdir(folder):
                if filename.endswith(".docx"):
                    filepath = os.path.join(folder, filename)
                    dataset.extend(extract_docx_features(filepath, label))

    return pd.DataFrame(dataset)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
data = load_dataset()

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
vectorizer = CountVectorizer()
X_text = vectorizer.fit_transform(data["text"])

X_combined = sp.hstack([
    X_text,
    np.array(data["font_size"].fillna(0)).reshape(-1, 1),
    np.array(data["bold"].fillna(0)).reshape(-1, 1),
    np.array(data["italic"].fillna(0)).reshape(-1, 1)
])

y = data["label"]

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É
X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.3, random_state=42)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
print("üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# –û—Ü–µ–Ω–∫–∞
y_pred = model.predict(X_test)
print("üìä –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
print(classification_report(y_test, y_pred))

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
os.makedirs("model", exist_ok=True)
joblib.dump(model, "model/gost_checker_model.pkl")
joblib.dump(vectorizer, "model/vectorizer.pkl")

print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø–∞–ø–∫–µ 'model'.")
