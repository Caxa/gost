import os
import pandas as pd
import joblib
import numpy as np
import scipy.sparse as sp
from docx import Document
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# === 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
def extract_docx_features(filepath, label):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç, —à—Ä–∏—Ñ—Ç –∏ —Å—Ç–∏–ª—å –∏–∑ .docx."""
    doc = Document(filepath)
    features = []

    for para in doc.paragraphs:
        if para.text.strip():  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            for run in para.runs:
                features.append({
                    "text": para.text.strip(),
                    "font_name": run.font.name or "Unknown",
                    "font_size": run.font.size.pt if run.font.size else 0,
                    "bold": int(run.bold or 0),
                    "italic": int(run.italic or 0),
                    "label": label
                })

    return features

# === 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ ===
def load_dataset():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ datasets/ –∏ —Å–æ–∑–¥–∞–µ—Ç DataFrame."""
    dataset = []

    for label, folder in [(1, "datasets/correct"), (0, "datasets/incorrect")]:
        if os.path.exists(folder):
            for filename in os.listdir(folder):
                if filename.endswith(".docx"):
                    filepath = os.path.join(folder, filename)
                    dataset.extend(extract_docx_features(filepath, label))

    return pd.DataFrame(dataset)

# === 3. –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è ===
def train_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –µ–µ –Ω–∞ –¥–∏—Å–∫."""
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    data = load_dataset()

    if data.empty:
        print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫–∏ datasets/correct –∏ datasets/incorrect.")
        return

    print(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Å—Ç—Ä–æ–∫.")
    print(data.head())  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    vectorizer = CountVectorizer()
    X_text = vectorizer.fit_transform(data["text"])

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–µ–∫—Å—Ç + —Å—Ç–∏–ª—å)
    X_combined = sp.hstack([
        X_text,
        np.array(data["font_size"]).reshape(-1, 1),
        np.array(data["bold"]).reshape(-1, 1),
        np.array(data["italic"]).reshape(-1, 1)
    ])

    y = data["label"]

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É
    X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.3, random_state=42)

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)

    # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
    y_pred = model.predict(X_test)
    print("\nüìä –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(classification_report(y_test, y_pred))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞
    os.makedirs("model", exist_ok=True)
    joblib.dump(model, "model/gost_checker_model.pkl")
    joblib.dump(vectorizer, "model/vectorizer.pkl")

    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø–∞–ø–∫–µ 'model'.")

# === 4. –ó–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    train_model()
